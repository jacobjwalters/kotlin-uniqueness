\section{\Lbase}

\Lbase is a simple typed language consisting of sequentially ordered statements with method calls. There are no modes, no classes, and no lambdas (or other methods of capturing).

\subsection{Syntax}
\begin{bnf}
  P ::=
    | $\overline{M}$  : Programs
    ;;
  M ::=
    | $m(\overline{x \Colon \tau}) \Colon \sigma \{ \Begin \Semi s \Semi \Return \, e \}$  : Method Definitions
    | $m(\overline{x \Colon \tau}) \Colon \sigma$  : Method Declarations
    ;;
  $\tau$, $\sigma$ ::=
    | $\Nat$ : Naturals
    | $\Bool$ : Booleans
    ;;
  $e$ ::=
    | $\Null$
    | $x$  : Variable Access
    | $m(\overline{e})$  : Method Call
    | $\True$
    | $\False$
    | $n \in \mathbb{N}$ : Natural Numbers
    ;;
  $s$ ::=
    | $\Var x : \tau$  : (Mutable) Variable Declaration
    | $x = e$  : Variable Assignment/Mutation
    | $s_1 \Semi s_2$  : Statement Sequencing
    | $\If e \Then s_1 \Else s_2$
    | $\Return e$  : Early Return
    | $m(\overline{e})$  : Method Call
    ;;
\end{bnf}

Overlined elements denote n-ary lists of such elements. $x$ and $m$ represent infinte sets of variable and method names respectively.

Non-forgetful differences from the system described by \textcite{protopapa2024VerifyingKotlinCode} are:
\begin{itemize}
\item Our system is typed (and has $\Nat$ and $\Bool$ as ground types)
\item ITE tests an arbitrary boolean expression, rather than direct equality on patterns.
\end{itemize}

For brevity's sake, we define $\Var x : \tau = e$ as $\Var x : \tau \Semi x = e$. Additionally, we assume usual boolean/arithmetic operators are defined as method call expressions.

\subsection{Typing Contexts}
Typing contexts (hereafter contexts) in \Lbase are (rightwards-growing) lists of variable names and their associated types. The grammar for contexts is as follows:

\begin{bnf}
  \Gamma ::=
    | $\cdot$ : Empty
    | $\Gamma, x : \tau$ : Extension
    ;;
\end{bnf}

Statements in \Lbase may alter their context, particular for variable declaration and (early) return statements. To model this, we take a small-step semantics like approach to dealing with contexts, with judgements of the form $\Gamma \vdash s \dashv Gamma'$.

\subsubsection{Well Formed Contexts}
We introduce a judgement $\Gamma \ctx$, to denote well formed contexts (WFCs). WFCs are defined inductively:
\[
  \inference[CtxEmp]{}{\cdot \ctx}

  \inference[CtxExt]{\Gamma \ctx & x \ni \Gamma}{\Gamma, x : \tau \ctx}
\]

$x \ni \Gamma$ is bookkeeping for ensuring all names are distinct, and isn't strictly needed. Membership checking and lookup are defined in the usual way.
\jq{Do we want to allow name reuse (and thus shadowing)? How will this interact with borrowing later on?}

We need a removal operator acting on the context, to remove local variables when leaving a scope. We define removal inductively:
\[
  \inference[RemoveEmp]{}{\cdot \setminus x = \cdot}
  \inference[RemoveVar]{}{\Gamma, x : \tau \setminus x = \Gamma}
  \inference[RemoveRec]{}{\Gamma, y : \tau \setminus x = \Gamma \setminus x, y : \tau}
\]
\jq{If we want shadowing, how should we deal with removal? With the above approach, we have no way of knowing which variables are declared in the local scope, and which are needed outside of the scope. My gut feeling is that we need a notion of stack frame in the context.}
